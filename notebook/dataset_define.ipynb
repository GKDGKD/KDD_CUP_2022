{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, time\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.500000</td>\n",
       "      <td>2666.760881</td>\n",
       "      <td>5986.126609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.826537</td>\n",
       "      <td>1829.842484</td>\n",
       "      <td>3346.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.250000</td>\n",
       "      <td>1014.935725</td>\n",
       "      <td>3182.294825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.500000</td>\n",
       "      <td>3246.541850</td>\n",
       "      <td>5841.894340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100.750000</td>\n",
       "      <td>4320.609625</td>\n",
       "      <td>8814.832950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>5501.452900</td>\n",
       "      <td>12121.004260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TurbID            x             y\n",
       "count  134.000000   134.000000    134.000000\n",
       "mean    67.500000  2666.760881   5986.126609\n",
       "std     38.826537  1829.842484   3346.503906\n",
       "min      1.000000     0.000000      0.000000\n",
       "25%     34.250000  1014.935725   3182.294825\n",
       "50%     67.500000  3246.541850   5841.894340\n",
       "75%    100.750000  4320.609625   8814.832950\n",
       "max    134.000000  5501.452900  12121.004260"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/' \n",
    "\n",
    "location_path = os.path.join(data_path, 'sdwpf_baidukddcup2022_turb_location.CSV')\n",
    "location      = pd.read_csv(location_path)\n",
    "location.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4727520, 13)\n",
      "Index(['TurbID', 'Day', 'Tmstamp', 'Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir',\n",
      "       'Pab1', 'Pab2', 'Pab3', 'Prtv', 'Patv'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv  \n",
       "0   NaN     NaN  \n",
       "1 -0.25  494.66  \n",
       "2 -0.24  509.76  \n",
       "3 -0.26  542.53  \n",
       "4 -0.23  509.36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, 'train/wtbdata_245days.csv')) \n",
    "print(df_train.shape)\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4727520, 15)\n",
      "Index(['TurbID', 'Day', 'Tmstamp', 'Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir',\n",
      "       'Pab1', 'Pab2', 'Pab3', 'Prtv', 'Patv', 'x', 'y'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00   NaN   NaN    NaN    NaN    NaN   NaN   NaN   NaN   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv          x           y  \n",
       "0   NaN     NaN  3349.8515  5939.23193  \n",
       "1 -0.25  494.66  3349.8515  5939.23193  \n",
       "2 -0.24  509.76  3349.8515  5939.23193  \n",
       "3 -0.26  542.53  3349.8515  5939.23193  \n",
       "4 -0.23  509.36  3349.8515  5939.23193  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.merge(df_train, location, on='TurbID', how='left')\n",
    "print(df_train.shape)\n",
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.727520e+06</td>\n",
       "      <td>4.727520e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.678002e+06</td>\n",
       "      <td>4.727520e+06</td>\n",
       "      <td>4.727520e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.750000e+01</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>5.028376e+00</td>\n",
       "      <td>4.975428e-01</td>\n",
       "      <td>4.110668e+01</td>\n",
       "      <td>2.739717e+01</td>\n",
       "      <td>1.885826e+02</td>\n",
       "      <td>2.685400e+01</td>\n",
       "      <td>2.683916e+01</td>\n",
       "      <td>2.682679e+01</td>\n",
       "      <td>-1.323900e+01</td>\n",
       "      <td>3.504458e+02</td>\n",
       "      <td>2.666761e+03</td>\n",
       "      <td>5.986127e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.868139e+01</td>\n",
       "      <td>7.072483e+01</td>\n",
       "      <td>3.393703e+00</td>\n",
       "      <td>3.160275e+01</td>\n",
       "      <td>8.529011e+01</td>\n",
       "      <td>1.832832e+01</td>\n",
       "      <td>1.632459e+02</td>\n",
       "      <td>3.883566e+01</td>\n",
       "      <td>3.882940e+01</td>\n",
       "      <td>3.882235e+01</td>\n",
       "      <td>7.044244e+01</td>\n",
       "      <td>4.249932e+02</td>\n",
       "      <td>1.823002e+03</td>\n",
       "      <td>3.333994e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.030460e+03</td>\n",
       "      <td>-2.730300e+02</td>\n",
       "      <td>-2.731700e+02</td>\n",
       "      <td>-8.848600e+02</td>\n",
       "      <td>-1.000000e+01</td>\n",
       "      <td>-1.000000e+01</td>\n",
       "      <td>-1.000000e+01</td>\n",
       "      <td>-6.249800e+02</td>\n",
       "      <td>-9.330000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>2.240000e+00</td>\n",
       "      <td>-3.830000e+00</td>\n",
       "      <td>1.405000e+01</td>\n",
       "      <td>2.006000e+01</td>\n",
       "      <td>6.302000e+01</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>-3.861000e+01</td>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>1.014317e+03</td>\n",
       "      <td>3.134452e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.750000e+01</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>4.340000e+00</td>\n",
       "      <td>-2.300000e-01</td>\n",
       "      <td>2.573000e+01</td>\n",
       "      <td>3.008000e+01</td>\n",
       "      <td>1.947900e+02</td>\n",
       "      <td>5.400000e-01</td>\n",
       "      <td>5.400000e-01</td>\n",
       "      <td>5.400000e-01</td>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>1.790800e+02</td>\n",
       "      <td>3.246542e+03</td>\n",
       "      <td>5.841894e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.840000e+02</td>\n",
       "      <td>7.010000e+00</td>\n",
       "      <td>3.420000e+00</td>\n",
       "      <td>3.273000e+01</td>\n",
       "      <td>3.682000e+01</td>\n",
       "      <td>3.219600e+02</td>\n",
       "      <td>8.399000e+01</td>\n",
       "      <td>8.398000e+01</td>\n",
       "      <td>8.398000e+01</td>\n",
       "      <td>-3.000000e-02</td>\n",
       "      <td>5.476600e+02</td>\n",
       "      <td>4.320683e+03</td>\n",
       "      <td>8.816238e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.340000e+02</td>\n",
       "      <td>2.450000e+02</td>\n",
       "      <td>2.629000e+01</td>\n",
       "      <td>2.266950e+03</td>\n",
       "      <td>3.943300e+02</td>\n",
       "      <td>3.242100e+02</td>\n",
       "      <td>7.006200e+02</td>\n",
       "      <td>9.998000e+01</td>\n",
       "      <td>9.998000e+01</td>\n",
       "      <td>9.998000e+01</td>\n",
       "      <td>4.852000e+02</td>\n",
       "      <td>1.567020e+03</td>\n",
       "      <td>5.501453e+03</td>\n",
       "      <td>1.212100e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TurbID           Day          Wspd          Wdir          Etmp  \\\n",
       "count  4.727520e+06  4.727520e+06  4.678002e+06  4.678002e+06  4.678002e+06   \n",
       "mean   6.750000e+01  1.230000e+02  5.028376e+00  4.975428e-01  4.110668e+01   \n",
       "std    3.868139e+01  7.072483e+01  3.393703e+00  3.160275e+01  8.529011e+01   \n",
       "min    1.000000e+00  1.000000e+00  0.000000e+00 -3.030460e+03 -2.730300e+02   \n",
       "25%    3.400000e+01  6.200000e+01  2.240000e+00 -3.830000e+00  1.405000e+01   \n",
       "50%    6.750000e+01  1.230000e+02  4.340000e+00 -2.300000e-01  2.573000e+01   \n",
       "75%    1.010000e+02  1.840000e+02  7.010000e+00  3.420000e+00  3.273000e+01   \n",
       "max    1.340000e+02  2.450000e+02  2.629000e+01  2.266950e+03  3.943300e+02   \n",
       "\n",
       "               Itmp          Ndir          Pab1          Pab2          Pab3  \\\n",
       "count  4.678002e+06  4.678002e+06  4.678002e+06  4.678002e+06  4.678002e+06   \n",
       "mean   2.739717e+01  1.885826e+02  2.685400e+01  2.683916e+01  2.682679e+01   \n",
       "std    1.832832e+01  1.632459e+02  3.883566e+01  3.882940e+01  3.882235e+01   \n",
       "min   -2.731700e+02 -8.848600e+02 -1.000000e+01 -1.000000e+01 -1.000000e+01   \n",
       "25%    2.006000e+01  6.302000e+01  1.000000e-02  1.000000e-02  1.000000e-02   \n",
       "50%    3.008000e+01  1.947900e+02  5.400000e-01  5.400000e-01  5.400000e-01   \n",
       "75%    3.682000e+01  3.219600e+02  8.399000e+01  8.398000e+01  8.398000e+01   \n",
       "max    3.242100e+02  7.006200e+02  9.998000e+01  9.998000e+01  9.998000e+01   \n",
       "\n",
       "               Prtv          Patv             x             y  \n",
       "count  4.678002e+06  4.678002e+06  4.727520e+06  4.727520e+06  \n",
       "mean  -1.323900e+01  3.504458e+02  2.666761e+03  5.986127e+03  \n",
       "std    7.044244e+01  4.249932e+02  1.823002e+03  3.333994e+03  \n",
       "min   -6.249800e+02 -9.330000e+00  0.000000e+00  0.000000e+00  \n",
       "25%   -3.861000e+01 -3.000000e-01  1.014317e+03  3.134452e+03  \n",
       "50%   -3.000000e-01  1.790800e+02  3.246542e+03  5.841894e+03  \n",
       "75%   -3.000000e-02  5.476600e+02  4.320683e+03  8.816238e+03  \n",
       "max    4.852000e+02  1.567020e+03  5.501453e+03  1.212100e+04  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.33\n",
      "-884.86 700.62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train['Patv'].min())\n",
    "print(df_train['Ndir'].min(), df_train['Ndir'].max())\n",
    "df_train['TurbID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "1. 用下一个值填补缺失值\n",
    "2. 将小于0的功率Patv值替换为0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TurbID', 'Day', 'Tmstamp', 'Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir',\n",
      "       'Pab1', 'Pab2', 'Pab3', 'Prtv', 'Patv', 'x', 'y'],\n",
      "      dtype='object')\n",
      "Index(['TurbID', 'Day', 'Wspd', 'Wdir', 'Etmp', 'Itmp', 'Ndir', 'Pab1', 'Pab2',\n",
      "       'Pab3', 'Prtv', 'Patv', 'x', 'y'],\n",
      "      dtype='object')\n",
      "总天数： 245\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_train.select_dtypes(include='number').columns)\n",
    "print('总天数：', len(df_train['Day'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值个数： 495180\n",
      "缺失值个数： 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv          x           y  \n",
       "0 -0.25  494.66  3349.8515  5939.23193  \n",
       "1 -0.25  494.66  3349.8515  5939.23193  \n",
       "2 -0.24  509.76  3349.8515  5939.23193  \n",
       "3 -0.26  542.53  3349.8515  5939.23193  \n",
       "4 -0.23  509.36  3349.8515  5939.23193  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'缺失值个数： {df_train.isna().sum().sum()}')\n",
    "df_train.fillna(method='bfill', inplace=True)\n",
    "print(f'缺失值个数： {df_train.isna().sum().sum()}')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df_train['Patv'] = df_train['Patv'].apply(lambda x: max(0, x))\n",
    "print(df_train['Patv'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逐个构建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['TurbID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Scaler(object):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.scaler.fit(data)\n",
    "\n",
    "    def transform(self, data):\n",
    "        return torch.tensor(self.scaler.transform(data), dtype=torch.float32)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return torch.tensor(self.scaler.inverse_transform(data), dtype=torch.float32)\n",
    "\n",
    "class WindTurbineDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Desc: Data preprocessing,\n",
    "          Here, e.g.    15 days for training,\n",
    "                        3 days for validation,\n",
    "                        and 6 days for testing\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path,\n",
    "                 filename='my.csv',\n",
    "                 flag='train',\n",
    "                 size=None,\n",
    "                 turbine_id=0,\n",
    "                 task='MS',\n",
    "                 target='Patv',\n",
    "                 scale=True,\n",
    "                 start_col=2,       # the start column index of the data one aims to utilize\n",
    "                 day_len=24 * 6,\n",
    "                 train_days=15,     # 15 days\n",
    "                 val_days=3,        # 3 days\n",
    "                 test_days=6,       # 6 days\n",
    "                 total_days=30      # 30 days\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.unit_size = day_len\n",
    "        if size is None:\n",
    "            self.input_len = self.unit_size\n",
    "            self.output_len = self.unit_size\n",
    "        else:\n",
    "            self.input_len = size[0]\n",
    "            self.output_len = size[1]\n",
    "        # initialization\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type  = type_map[flag]\n",
    "        self.task      = task\n",
    "        self.target    = target\n",
    "        self.scale     = scale\n",
    "        self.start_col = start_col\n",
    "        self.data_path = data_path\n",
    "        self.filename  = filename\n",
    "        self.tid       = turbine_id\n",
    "\n",
    "        # If needed, we employ the predefined total_size (e.g. one month)\n",
    "        self.total_size = self.unit_size * total_days\n",
    "        #\n",
    "        self.train_size = train_days * self.unit_size\n",
    "        self.val_size   = val_days * self.unit_size\n",
    "        self.test_size  = test_days * self.unit_size\n",
    "        # self.test_size = self.total_size - train_size - val_size\n",
    "        #\n",
    "        # Or, if total_size is unavailable:\n",
    "        # self.total_size = self.train_size + self.val_size + self.test_size\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = Scaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.data_path, self.filename))\n",
    "        \n",
    "        \n",
    "        border1s = [self.tid * self.total_size,\n",
    "                    self.tid * self.total_size + self.train_size - self.input_len,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size - self.input_len\n",
    "                    ]\n",
    "        border2s = [self.tid * self.total_size + self.train_size,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size,\n",
    "                    self.tid * self.total_size + self.train_size + self.val_size + self.test_size\n",
    "                    ]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        df_data = df_raw\n",
    "        if self.task == 'M':\n",
    "            cols_data = df_raw.columns[self.start_col:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.task == 'MS':\n",
    "            cols_data = df_raw.columns[self.start_col:]\n",
    "            df_data = df_raw[cols_data]\n",
    "        elif self.task == 'S': \n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        # Turn off the SettingWithCopyWarning\n",
    "        pd.set_option('mode.chained_assignment', None)\n",
    "        # df_data.replace(to_replace=np.nan, value=0, inplace=True)\n",
    "        df_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "        self.data_x   = data[border1:border2]\n",
    "        self.data_y   = data[border1:border2]\n",
    "        self.raw_data = df_data[border1 + self.input_len:border2]\n",
    "\n",
    "    def get_raw_data(self):\n",
    "        return self.raw_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #\n",
    "        # Only for customized use.\n",
    "        # When sliding window not used, e.g. prediction without overlapped input/output sequences\n",
    "        if self.set_type >= 3:\n",
    "            index = index * self.output_len\n",
    "        #\n",
    "        # Standard use goes here.\n",
    "        # Sliding window with the size of input_len + output_len\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.input_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.output_len\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        self.target_col = self.raw_data.columns.get_loc(self.target)\n",
    "        seq_y = self.data_y[r_begin:r_end, self.target_col]\n",
    "        return seq_x, seq_y\n",
    "\n",
    "    def __len__(self):\n",
    "        # In our case, the sliding window is adopted, the number of samples is calculated as follows\n",
    "        if self.set_type < 3:\n",
    "            return len(self.data_x) - self.input_len - self.output_len + 1\n",
    "        # Otherwise, if sliding window is not adopted\n",
    "        return int((len(self.data_x) - self.input_len) / self.output_len)\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        if data.ndim > 1:\n",
    "            return self.scaler.inverse_transform(data)\n",
    "        else:\n",
    "            # 逆标准化y\n",
    "            num_features = self.raw_data.shape[1]\n",
    "            tmp = torch.ones(len(data), num_features - 1)\n",
    "            tmp = torch.cat([tmp, data.reshape(-1, 1)], dim=1)\n",
    "            # Note: 默认最后一列为目标变量\n",
    "            y_inverse = self.scaler.inverse_transform(tmp)[:, -1] \n",
    "    \n",
    "            return y_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path  = '../data/train/'\n",
    "filename   = 'wtbdata_245days.csv'\n",
    "flag       = 'train'\n",
    "input_len  = 288\n",
    "output_len = 288\n",
    "size       = [input_len, output_len]\n",
    "task       = 'MS'\n",
    "target     = 'Patv'\n",
    "start_col  = 3\n",
    "turbine_id = 0\n",
    "day_len    = 144\n",
    "train_days = 240\n",
    "val_days   = 3\n",
    "test_days  = 2\n",
    "total_days = 245\n",
    "\n",
    "data_train = WindTurbineDataset(\n",
    "    data_path  = data_path,\n",
    "    filename   = filename,\n",
    "    flag       = flag,\n",
    "    size       = size,\n",
    "    task       = task,\n",
    "    target     = target,\n",
    "    start_col  = start_col,\n",
    "    turbine_id = turbine_id,\n",
    "    day_len    = day_len,\n",
    "    train_days = train_days,\n",
    "    val_days   = val_days,\n",
    "    test_days  = test_days,\n",
    "    total_days = total_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33985\n",
      "torch.Size([288, 10]) torch.Size([288])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1945, -0.1354,  0.5203,  ..., -0.2526,  0.0676,  0.0513],\n",
       "        [ 0.1945, -0.1354,  0.5203,  ..., -0.2526,  0.0676,  0.0513],\n",
       "        [ 0.2220, -0.0859,  0.5129,  ..., -0.2526,  0.0678,  0.0798],\n",
       "        ...,\n",
       "        [ 1.7905,  0.0162,  0.3305,  ..., -0.2491,  0.0692,  2.0438],\n",
       "        [ 1.7411, -0.0211,  0.3192,  ..., -0.2496,  0.0692,  2.0436],\n",
       "        [ 1.7301, -0.0777,  0.3079,  ..., -0.2496,  0.0695,  2.0431]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, y1 = data_train[0]\n",
    "print(len(data_train))\n",
    "print(x1.shape, y1.shape)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0433,  1.9946,  1.9480,  2.0323,  1.9579,  1.9507,  2.0446,  2.0440,\n",
       "         2.0436,  2.0431,  1.9301,  1.9539,  1.4521,  0.0615,  0.4948,  0.7868,\n",
       "         0.6457,  1.0694,  1.2208,  0.9012,  1.1156,  1.2710,  1.5628,  2.0443,\n",
       "         2.0036,  1.8960,  2.0435,  2.0436,  1.9649,  2.0056,  2.0435,  2.0432,\n",
       "         2.0434,  2.0363,  2.0241,  2.0207,  2.0350,  2.0426,  1.9964,  1.9533,\n",
       "         1.9836,  1.9664,  1.8514,  1.8933,  1.9984,  2.0438,  2.0433,  2.0303,\n",
       "         2.0197,  1.9645,  1.9644,  2.0059,  1.9001,  1.9920,  1.8765,  1.6576,\n",
       "         1.8294,  1.7982,  1.9145,  1.9340,  1.8101,  1.7851,  1.8236,  1.8956,\n",
       "         1.9445,  1.8997,  2.0280,  1.9624,  1.8880,  1.9861,  1.9218,  1.9862,\n",
       "         1.9743,  1.9755,  2.0122,  2.0138,  2.0305,  2.0211,  2.0092,  2.0367,\n",
       "         2.0025,  1.9993,  1.9749,  2.0118,  1.8987,  1.9060,  1.8882,  1.8933,\n",
       "         1.8783,  1.9916,  1.9582,  1.9024,  1.7269,  1.6999,  1.7181,  1.7688,\n",
       "         1.6678,  1.6652,  1.6096,  1.8168,  1.8526,  1.7798,  1.9907,  1.9739,\n",
       "         1.9075,  1.9712,  1.9921,  2.0096,  1.9678,  1.9513,  1.9645,  1.8888,\n",
       "         1.9811,  1.9664,  1.9316,  1.9146,  1.9304,  2.0076,  1.9905,  1.9507,\n",
       "         2.0231,  2.0087,  1.9938,  2.0007,  1.9737,  2.0202,  1.9545,  1.8755,\n",
       "         1.7301,  1.9602,  2.0312,  1.9871,  2.0088,  1.9763,  2.0021,  1.9993,\n",
       "         2.0270,  1.9958,  2.0299,  2.0432,  2.0429,  2.0373,  2.0253,  2.0280,\n",
       "         1.9261,  1.7776,  1.6334,  1.9805,  2.0352,  1.8236,  1.9930,  1.9645,\n",
       "         2.0077,  2.0063,  2.0028,  1.9806,  1.9659,  1.9915,  2.0288,  2.0231,\n",
       "         2.0344,  2.0411,  2.0329,  2.0442,  2.0431,  2.0287,  2.0408,  2.0147,\n",
       "         2.0297,  2.0335,  2.0193,  2.0281,  1.9862,  2.0158,  2.0206,  1.9757,\n",
       "         1.9965,  1.9876,  2.0178,  1.8574,  2.0342,  2.0101,  2.0370,  2.0095,\n",
       "         2.0063,  2.0110,  1.9542,  2.0110,  2.0082,  1.9734,  2.0132,  1.9499,\n",
       "         2.0152,  1.9333,  1.8849,  1.8847,  1.9863,  1.9645,  1.9706,  2.0040,\n",
       "         1.9577,  1.9703,  0.5106,  2.0437,  2.0429,  2.0443,  2.0430,  2.0300,\n",
       "         2.0388,  2.0143,  2.0265,  2.0020,  2.0438,  2.0305,  2.0150,  2.0308,\n",
       "         2.0426,  2.0032,  2.0361,  2.0297,  2.0170,  2.0408,  2.0279,  2.0204,\n",
       "         2.0175,  1.9656,  1.8638,  1.9199,  1.8019,  1.7170,  1.7671,  1.8233,\n",
       "         1.4164,  1.4334,  1.3276,  1.4753,  0.8342,  0.9605,  1.0662,  0.8546,\n",
       "         0.3288,  0.6471,  0.4146,  0.0098,  0.3352,  0.0840,  0.0525, -0.0168,\n",
       "         0.0455, -0.0589, -0.0995, -0.0748, -0.0624, -0.1604,  0.0416,  0.1859,\n",
       "        -0.0477, -0.1658, -0.1909, -0.1230, -0.3274, -0.1516, -0.2395, -0.1023,\n",
       "         0.0067, -0.0504, -0.1168, -0.3216, -0.3599, -0.4324, -0.3103, -0.2780,\n",
       "        -0.3539, -0.4528,  0.0396,  0.6318,  1.1462,  1.1566,  1.0687,  1.1852,\n",
       "         1.2967,  1.3665,  1.3538,  1.1999,  1.3355,  1.4590,  1.5510,  1.6563])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34272, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>11.45</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>26.84</td>\n",
       "      <td>40.28</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1549.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>10.93</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>26.68</td>\n",
       "      <td>40.33</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>1523.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>10.69</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>26.55</td>\n",
       "      <td>40.40</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1499.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>11.54</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>26.45</td>\n",
       "      <td>40.34</td>\n",
       "      <td>5.63</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1543.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>10.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>26.34</td>\n",
       "      <td>40.29</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>1504.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wspd  Wdir   Etmp   Itmp  Ndir  Pab1  Pab2  Pab3  Prtv     Patv\n",
       "288  11.45 -2.16  26.84  40.28  7.42  1.05  1.05  1.05 -0.18  1549.45\n",
       "289  10.93 -2.96  26.68  40.33  7.42  1.03  1.03  1.03 -0.24  1523.67\n",
       "290  10.69 -4.61  26.55  40.40  7.42  1.01  1.01  1.01 -0.26  1499.01\n",
       "291  11.54 -4.08  26.45  40.34  5.63  1.05  1.05  1.05 -0.27  1543.64\n",
       "292  10.63  0.55  26.34  40.29 -0.27  1.02  1.02  1.02 -0.28  1504.23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = data_train.get_raw_data()\n",
    "print(df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "torch.Size([34560, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0433,  1.9946,  1.9480,  ..., -0.8583, -0.8825, -0.8835])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = df_raw.columns.get_loc('Patv')\n",
    "print(target_col)\n",
    "print(data_train.data_y.shape)\n",
    "data_train.data_y[input_len:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1549.4500, 1523.6700, 1499.0100, 1543.6399, 1504.2300, 1500.4500,\n",
       "        1550.1699, 1549.8201, 1549.6499, 1549.3700, 1489.5100, 1502.1100,\n",
       "        1236.4200,  500.0700,  729.5200,  884.1100,  809.4300, 1033.7600,\n",
       "        1113.9401,  944.7100, 1058.2600, 1140.5000, 1295.0400, 1550.0200,\n",
       "        1528.4399, 1471.4800, 1549.5900, 1549.6101, 1507.9301, 1529.4900,\n",
       "        1549.5499, 1549.4301, 1549.5200, 1545.7799, 1539.2899, 1537.4900,\n",
       "        1545.0699, 1549.0800, 1524.6400, 1501.8099, 1517.8800, 1508.7400,\n",
       "        1447.8700, 1470.0500, 1525.7000, 1549.7200, 1549.4900, 1542.6001,\n",
       "        1536.9900, 1507.7300, 1507.6799, 1529.6899, 1473.6300, 1522.3201,\n",
       "        1461.1200, 1345.2200, 1436.2000, 1419.6901, 1481.2600, 1491.6000,\n",
       "        1425.9800, 1412.7400, 1433.1200, 1471.2500, 1497.1700, 1473.4401,\n",
       "        1541.3900, 1506.6400, 1467.2100, 1519.1901, 1485.1100, 1519.2600,\n",
       "        1512.9100, 1513.5900, 1532.9800, 1533.8700, 1542.6699, 1537.7000,\n",
       "        1531.4000, 1545.9600, 1527.8800, 1526.1901, 1513.2300, 1532.7900,\n",
       "        1472.9100, 1476.7800, 1467.3500, 1470.0500, 1462.0900, 1522.0699,\n",
       "        1504.4200, 1474.8500, 1381.9100, 1367.6400, 1377.2700, 1404.1100,\n",
       "        1350.6600, 1349.2400, 1319.8000, 1429.5200, 1448.4800, 1409.9600,\n",
       "        1521.6100, 1512.7300, 1477.5500, 1511.2900, 1522.3700, 1531.6100,\n",
       "        1509.5100, 1500.7300, 1507.7600, 1467.6500, 1516.5300, 1508.7500,\n",
       "        1490.3400, 1481.3000, 1489.6799, 1530.5599, 1521.4900, 1500.4100,\n",
       "        1538.8000, 1531.1500, 1523.2700, 1526.9000, 1512.6400, 1537.2300,\n",
       "        1502.4700, 1460.6100, 1383.6200, 1505.4900, 1543.0599, 1519.6899,\n",
       "        1531.2200, 1513.9800, 1527.6499, 1526.1901, 1540.8600, 1524.3300,\n",
       "        1542.3600, 1549.4301, 1549.2800, 1546.2999, 1539.9500, 1541.3800,\n",
       "        1487.4301, 1408.7600, 1332.4199, 1516.1901, 1545.1599, 1433.1500,\n",
       "        1522.8600, 1507.7200, 1530.6300, 1529.8700, 1528.0299, 1516.2600,\n",
       "        1508.5100, 1522.0400, 1541.7700, 1538.7699, 1544.7600, 1548.3201,\n",
       "        1543.9500, 1549.9501, 1549.3700, 1541.7400, 1548.1400, 1534.3401,\n",
       "        1542.2700, 1544.2599, 1536.7600, 1541.4399, 1519.2600, 1534.9301,\n",
       "        1537.4401, 1513.6700, 1524.6700, 1519.9900, 1535.9700, 1451.0100,\n",
       "        1544.6700, 1531.9100, 1546.1100, 1531.5801, 1529.8600, 1532.3700,\n",
       "        1502.2800, 1532.3800, 1530.8900, 1512.4800, 1533.5199, 1500.0000,\n",
       "        1534.5699, 1491.2300, 1465.6100, 1465.4900, 1519.3101, 1507.7300,\n",
       "        1510.9900, 1528.6700, 1504.1600, 1510.8201,  737.9000, 1549.6600,\n",
       "        1549.2699, 1549.9900, 1549.3301, 1542.4399, 1547.1100, 1534.1300,\n",
       "        1540.5901, 1527.6200, 1549.7500, 1542.6699, 1534.5000, 1542.8600,\n",
       "        1549.0901, 1528.2301, 1545.6600, 1542.2500, 1535.5199, 1548.1200,\n",
       "        1541.2999, 1537.3300, 1535.7999, 1508.3400, 1454.4299, 1484.1500,\n",
       "        1421.6700, 1376.6699, 1403.2000, 1432.9800, 1217.4900, 1226.4900,\n",
       "        1170.4700, 1248.7200,  909.2400,  976.1200, 1032.1000,  920.0200,\n",
       "         641.6100,  810.1300,  687.0600,  472.6700,  645.0200,  512.0000,\n",
       "         495.2900,  458.6300,  491.5800,  436.3200,  414.8000,  427.8900,\n",
       "         434.4800,  382.5800,  489.5400,  565.9400,  442.2200,  379.6800,\n",
       "         366.4200,  402.3700,  294.1400,  387.2300,  340.6600,  413.3400,\n",
       "         471.0700,  440.8300,  405.6600,  297.2000,  276.9300,  238.5400,\n",
       "         303.1700,  320.3200,  280.0800,  227.7300,  488.4500,  802.0500,\n",
       "        1074.4600, 1079.9500, 1033.4200, 1095.1100, 1154.1300, 1191.0801,\n",
       "        1184.3600, 1102.8500, 1174.6500, 1240.0499, 1288.8099, 1344.5200])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.inverse_transform(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.1700e+00, -3.9900e+00,  3.0730e+01,  ...,  1.0000e+00,\n",
       "         -2.5000e-01,  4.9466e+02],\n",
       "        [ 6.1700e+00, -3.9900e+00,  3.0730e+01,  ...,  1.0000e+00,\n",
       "         -2.5000e-01,  4.9466e+02],\n",
       "        [ 6.2700e+00, -2.1800e+00,  3.0600e+01,  ...,  1.0000e+00,\n",
       "         -2.4000e-01,  5.0976e+02],\n",
       "        ...,\n",
       "        [ 1.1980e+01,  1.5500e+00,  2.7370e+01,  ...,  1.0700e+00,\n",
       "         -1.9000e-01,  1.5497e+03],\n",
       "        [ 1.1800e+01,  1.9000e-01,  2.7170e+01,  ...,  1.0600e+00,\n",
       "         -1.9000e-01,  1.5496e+03],\n",
       "        [ 1.1760e+01, -1.8800e+00,  2.6970e+01,  ...,  1.0600e+00,\n",
       "         -1.8000e-01,  1.5493e+03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.inverse_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>6.17</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>30.73</td>\n",
       "      <td>41.80</td>\n",
       "      <td>25.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>494.66</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>30.60</td>\n",
       "      <td>41.63</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>509.76</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>6.42</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>30.52</td>\n",
       "      <td>41.52</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>542.53</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.89</td>\n",
       "      <td>30.49</td>\n",
       "      <td>41.38</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>509.36</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:50</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>30.47</td>\n",
       "      <td>41.22</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>482.21</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01:00</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.07</td>\n",
       "      <td>30.31</td>\n",
       "      <td>41.19</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>584.75</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01:10</td>\n",
       "      <td>6.70</td>\n",
       "      <td>-2.80</td>\n",
       "      <td>30.24</td>\n",
       "      <td>41.00</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>557.98</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01:20</td>\n",
       "      <td>6.44</td>\n",
       "      <td>-3.46</td>\n",
       "      <td>30.13</td>\n",
       "      <td>40.91</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>503.94</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01:30</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>29.97</td>\n",
       "      <td>40.72</td>\n",
       "      <td>20.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>463.37</td>\n",
       "      <td>3349.8515</td>\n",
       "      <td>5939.23193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp   Ndir  Pab1  Pab2  Pab3  \\\n",
       "0       1    1   00:00  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "1       1    1   00:10  6.17 -3.99  30.73  41.80  25.92   1.0   1.0   1.0   \n",
       "2       1    1   00:20  6.27 -2.18  30.60  41.63  20.91   1.0   1.0   1.0   \n",
       "3       1    1   00:30  6.42 -0.73  30.52  41.52  20.91   1.0   1.0   1.0   \n",
       "4       1    1   00:40  6.25  0.89  30.49  41.38  20.91   1.0   1.0   1.0   \n",
       "5       1    1   00:50  6.10 -1.03  30.47  41.22  20.91   1.0   1.0   1.0   \n",
       "6       1    1   01:00  6.77  1.07  30.31  41.19  20.91   1.0   1.0   1.0   \n",
       "7       1    1   01:10  6.70 -2.80  30.24  41.00  20.91   1.0   1.0   1.0   \n",
       "8       1    1   01:20  6.44 -3.46  30.13  40.91  20.91   1.0   1.0   1.0   \n",
       "9       1    1   01:30  6.25 -3.15  29.97  40.72  20.91   1.0   1.0   1.0   \n",
       "\n",
       "   Prtv    Patv          x           y  \n",
       "0 -0.25  494.66  3349.8515  5939.23193  \n",
       "1 -0.25  494.66  3349.8515  5939.23193  \n",
       "2 -0.24  509.76  3349.8515  5939.23193  \n",
       "3 -0.26  542.53  3349.8515  5939.23193  \n",
       "4 -0.23  509.36  3349.8515  5939.23193  \n",
       "5 -0.27  482.21  3349.8515  5939.23193  \n",
       "6 -0.23  584.75  3349.8515  5939.23193  \n",
       "7 -0.23  557.98  3349.8515  5939.23193  \n",
       "8 -0.21  503.94  3349.8515  5939.23193  \n",
       "9 -0.26  463.37  3349.8515  5939.23193  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288, 10]) torch.Size([288])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.1700e+00, -3.9900e+00,  3.0730e+01,  ...,  1.0000e+00,\n",
       "         -2.5000e-01,  4.9466e+02],\n",
       "        [ 6.2700e+00, -2.1800e+00,  3.0600e+01,  ...,  1.0000e+00,\n",
       "         -2.4000e-01,  5.0976e+02],\n",
       "        [ 6.4200e+00, -7.3000e-01,  3.0520e+01,  ...,  1.0000e+00,\n",
       "         -2.6000e-01,  5.4253e+02],\n",
       "        ...,\n",
       "        [ 1.1800e+01,  1.9000e-01,  2.7170e+01,  ...,  1.0600e+00,\n",
       "         -1.9000e-01,  1.5496e+03],\n",
       "        [ 1.1760e+01, -1.8800e+00,  2.6970e+01,  ...,  1.0600e+00,\n",
       "         -1.8000e-01,  1.5493e+03],\n",
       "        [ 1.1450e+01, -2.1600e+00,  2.6840e+01,  ...,  1.0500e+00,\n",
       "         -1.8000e-01,  1.5494e+03]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y2 = data_train[1]\n",
    "print(x2.shape, y2.shape)\n",
    "data_train.inverse_transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([288, 10])\n",
      "torch.Size([288, 64]) torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "model_rnn = nn.RNN(input_size=x1.shape[1], hidden_size=64, num_layers=2, batch_first=True)\n",
    "out, hn = model_rnn(x1)\n",
    "print(out.shape, hn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n",
      "torch.Size([288, 10]) torch.Size([288])\n"
     ]
    }
   ],
   "source": [
    "data_val = WindTurbineDataset(\n",
    "    data_path  = data_path,\n",
    "    filename   = filename,\n",
    "    flag       = 'val',\n",
    "    size       = size,\n",
    "    task       = task,\n",
    "    target     = target,\n",
    "    start_col  = start_col,\n",
    "    turbine_id = turbine_id,\n",
    "    day_len    = day_len,\n",
    "    train_days = train_days,\n",
    "    val_days   = val_days,\n",
    "    test_days  = test_days,\n",
    "    total_days = total_days\n",
    ")\n",
    "\n",
    "print(len(data_val))\n",
    "v1x, v1y = data_val[1]\n",
    "print(v1x.shape, v1y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n",
    "\n",
    "#### Input:\n",
    "$(N, L, H_{in})$ when batch_first=True; <br>\n",
    "$N$ = batch size; <br>\n",
    "$L$ = sequence length; <br>\n",
    "$H_{in}$ = input size\n",
    "\n",
    "#### Output:\n",
    "output: $(N, L, D*H_{out})$ <br>\n",
    "$h_n$: 隐层输出.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, \n",
    "                 hidden_size, \n",
    "                 output_size,\n",
    "                 num_layers=1,\n",
    "                 activation = 'tanh',\n",
    "                 dropout=0,\n",
    "                 device='cpu',\n",
    "                 batch_first=True\n",
    "                 ):\n",
    "        super(RNN, self).__init__()\n",
    "        assert activation in ['tanh', 'relu']\n",
    "        self.input_size  = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers  = num_layers\n",
    "        self.device      = device\n",
    "        self.dropout     = dropout\n",
    "        self.activation  = activation\n",
    "        self.batch_first = batch_first\n",
    "        self.model = nn.Sequential(\n",
    "            nn.RNN(input_size=self.input_size, \n",
    "                   hidden_size  = self.hidden_size,\n",
    "                   num_layers   = self.num_layers,\n",
    "                   nonlinearity = self.activation,\n",
    "                   dropout      = self.dropout,\n",
    "                   batch_first  = self.batch_first),\n",
    "            nn.Linear(self.hidden_size, self.output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # x: (batch_size, sequence_length, input_size)\n",
    "        out, _ = self.model[0](x)\n",
    "        # out: (batch_size, sequence_length, hidden_size)\n",
    "        out = self.model[1](out[:, -1, :])\n",
    "        # out: (batch_size, output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionEstimator():\n",
    "    def __init__(self, model, crit, max_epochs, batch_size, device, optimizer, scheduler, \n",
    "                 verbose=False, logger=None):\n",
    "        self.model      = model\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device     = device\n",
    "        self.verbose    = verbose  # control whether output the training process, bool.\n",
    "        self.crit       = crit  # loss function\n",
    "        self.optimizer  = optimizer\n",
    "        self.scheduler  = scheduler\n",
    "        self.logger     = logger\n",
    "\n",
    "    def fit(self, X_train, Y_train, X_valid=None, Y_valid=None, patience=5):\n",
    "\n",
    "        train_data = TensorDataset(X_train, Y_train)\n",
    "        train_dataloader = DataLoader(\n",
    "            dataset=train_data, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        model     = self.model.to(self.device)\n",
    "        optimizer = self.optimizer\n",
    "        scheduler = self.scheduler\n",
    "        train_loss_history = []\n",
    "        validation_loss_history = []\n",
    "        best_validation_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            start_time = time.time()\n",
    "            loss_all = []\n",
    "            model.train()\n",
    "\n",
    "            for data in train_dataloader:\n",
    "                x, y = data\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = model(x)\n",
    "                loss = self.crit(out, y)\n",
    "                loss.requires_grad_(True)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                loss_all.append(loss.item())\n",
    "\n",
    "            scheduler.step()\n",
    "            end_time = time.time()\n",
    "            cost_time = end_time - start_time\n",
    "\n",
    "            train_loss = np.mean(np.array(loss_all))\n",
    "            train_loss_history.append(train_loss)\n",
    "\n",
    "            # '---------------evaluating model on validation set------------------'\n",
    "            if X_valid is not None:\n",
    "                model.eval()\n",
    "                valid_data = TensorDataset(X_valid, Y_valid)\n",
    "                validation_dataloader = DataLoader(\n",
    "                    dataset=valid_data, batch_size=self.batch_size, shuffle=False)\n",
    "                loss_all = []\n",
    "                with torch.no_grad():\n",
    "                    for data in validation_dataloader:\n",
    "                        x, y = data\n",
    "                        x = x.to(self.device)\n",
    "                        y = y.to(self.device)\n",
    "                        output = model(x)\n",
    "                        loss = self.crit(output, y)\n",
    "                        loss_all.append(loss.item())\n",
    "\n",
    "                validation_loss = np.mean(np.array(loss_all))\n",
    "                validation_loss_history.append(validation_loss)\n",
    "                \n",
    "                if self.verbose and (epoch+1) % 100 == 0:\n",
    "                    if self.logger:\n",
    "                        self.logger.info('Epoch:{:d}, train_loss: {:.4f}, validation_loss: {:.4f}, cost_time: {:.2f}s'\n",
    "                                         .format(epoch+1, train_loss, validation_loss, cost_time))\n",
    "                    else:\n",
    "                        print('Epoch:{:d}, train_loss: {:.4f}, validation_loss: {:.4f}, cost_time: {:.2f}s'\n",
    "                              .format(epoch+1, train_loss, validation_loss, cost_time))\n",
    "\n",
    "                # 早停策略：val_loss 超过 patience 个 epoch 没提升就停止训练\n",
    "                if validation_loss < best_validation_loss:\n",
    "                    best_validation_loss = validation_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    if self.logger:\n",
    "                        self.logger.info(f'Early stopping after {patience} epochs without improvement.')\n",
    "                    else:\n",
    "                        print(f'Early stopping after {patience} epochs without improvement.')\n",
    "                    break\n",
    "            else:\n",
    "                if self.verbose and (epoch+1) % 100 == 0:\n",
    "                    print('Epoch:{:d}, train_loss: {:.4f}, cost_time: {:.2f}s'\n",
    "                          .format(epoch+1, train_loss, cost_time))\n",
    "\n",
    "        return train_loss_history, validation_loss_history\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        model = self.model.to(self.device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = x.to(self.device)\n",
    "            pred = model(x)\n",
    "\n",
    "        res = pred.data.cpu().numpy()\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33985\n",
      "3399\n"
     ]
    }
   ],
   "source": [
    "# x1_train_tensor = torch.from_numpy(x1_train).float()\n",
    "# print(x1_train.shape)\n",
    "\n",
    "# model_rnn = nn.RNN(input_size=x1_train.shape[2], hidden_size=64, num_layers=2, batch_first=True)\n",
    "# out, hn = model_rnn(x1_train_tensor)\n",
    "\n",
    "batch_size = 10\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=data_train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(len(data_train))\n",
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, batch_x.shape: torch.Size([10, 288, 10]), batch_y.shape: torch.Size([10, 288]), out.shape: torch.Size([10, 288])\n",
      "i: 1, batch_x.shape: torch.Size([10, 288, 10]), batch_y.shape: torch.Size([10, 288]), out.shape: torch.Size([10, 288])\n"
     ]
    }
   ],
   "source": [
    "output_len = 24*6*2\n",
    "model_rnn = RNN(input_size=x1.shape[1], hidden_size=32, output_size=output_len)\n",
    "\n",
    "counter = 0\n",
    "for i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "    if counter > 1:\n",
    "        break\n",
    "    out = model_rnn(batch_x)\n",
    "    print(f'i: {i}, batch_x.shape: {batch_x.shape}, batch_y.shape: {batch_y.shape}, out.shape: {out.shape}')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_val(data_train, data_val, model, criterion, config, logger=None):\n",
    "    loader_train = DataLoader(dataset=data_train, batch_size=config['batch_size'], shuffle=config['shuffle_train_val'])\n",
    "    loader_val   = DataLoader(dataset=data_val, batch_size=config['batch_size'], shuffle=config['shuffle_test'])\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'device: ', device)\n",
    "    best_validation_loss = float('inf')\n",
    "    patience_counter     = 0\n",
    "    patience             = config['patience']\n",
    "    train_loss_history   = []\n",
    "    val_loss_history     = []\n",
    "    \n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr_rate']) # 这两个不能放外面\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                step_size=config['lr_step_size'], \n",
    "                                                gamma=config['lr_gamma'])\n",
    "    \n",
    "    for epoch in range(config['max_epoch']):\n",
    "        train_loss = []\n",
    "        epoch_start_time = time.time()\n",
    "        # model.train()\n",
    "        for x, y in loader_train:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            print(f'x.device: {x.device}, y.device: {y.device}, model.device: {model.device}')\n",
    "            optimizer.zero_grad()\n",
    "            out  = model(x)\n",
    "            print(f'out.device: {out.device}, y.device:{y.device}')\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        train_loss_epoch = np.mean(train_loss)\n",
    "        train_loss_history.append(train_loss_epoch)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            for x, y in loader_val:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "                val_loss.append(loss.item())\n",
    "        val_loss_epoch = np.mean(val_loss)\n",
    "        val_loss_history.append(val_loss_epoch)\n",
    "        epoch_end_time = time.time()\n",
    "        cost_time = epoch_end_time - epoch_start_time\n",
    "\n",
    "        # 早停\n",
    "        if val_loss_epoch < best_validation_loss:\n",
    "            best_validation_loss = val_loss_epoch\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            if logger:\n",
    "                logger.info(f'Early stopping after {patience} epochs without improvement.')\n",
    "            else:\n",
    "                print(f'Early stopping after {patience} epochs without improvement.')\n",
    "            break\n",
    "        \n",
    "        if logger:\n",
    "            logger.info('Epoch:{:d}, train_loss: {:.4f}, validation_loss: {:.4f}, cost time: {:.2f}s'.format(epoch + 1, \n",
    "                                                                                                             train_loss_epoch, \n",
    "                                                                                                             val_loss_epoch,\n",
    "                                                                                                             cost_time))\n",
    "        else:\n",
    "            print('Epoch:{:d}, train_loss: {:.4f}, validation_loss: {:.4f}, cost time: {:.2f}s'.format(epoch + 1, \n",
    "                                                                                                             train_loss_epoch, \n",
    "                                                                                                             val_loss_epoch,\n",
    "                                                                                                             cost_time))\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda\n",
      "x.device: cuda:0, y.device: cuda:0, model.device: cpu\n",
      "out.device: cpu, y.device:cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m model_rnn \u001b[38;5;241m=\u001b[39m RNN(input_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m], hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, output_size\u001b[38;5;241m=\u001b[39moutput_len)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mtrain_and_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[95], line 29\u001b[0m, in \u001b[0;36mtrain_and_val\u001b[1;34m(data_train, data_val, model, criterion, config, logger)\u001b[0m\n\u001b[0;32m     27\u001b[0m out  \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y.device:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\LLiiH\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LLiiH\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LLiiH\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LLiiH\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:3329\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3326\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3328\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\n",
    "    'input_size'       : 10,\n",
    "    'hidden_size'      : 32,\n",
    "    'output_size'      : output_len,\n",
    "    'num_layers'       : 1,\n",
    "    'device'           : 'cuda',\n",
    "    'batch_size'       : 10,\n",
    "    'lr_rate'          : 0.01,\n",
    "    'max_epoch'        : 100,\n",
    "    'patience'         : 5,\n",
    "    'shuffle_train_val': True,\n",
    "    'shuffle_test'     : False,\n",
    "    'lr_step_size'     : 30,\n",
    "    'lr_gamma'         : 0.9\n",
    "}\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "model_rnn = RNN(input_size=config['input_size'], hidden_size=32, output_size=output_len)\n",
    "\n",
    "train_and_val(data_train, data_val, model_rnn, criterion, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cpu\n",
      "model2.device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(model_rnn.device)\n",
    "model2 = model_rnn.to(device)\n",
    "print('model2.device:', next(model2.parameters()).device)\n",
    "model2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model_rnn.to(device)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model_rnn.device\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "# model_rnn.to(device)\n",
    "# model_rnn.device\n",
    "\n",
    "model2.parameters.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([288, 10]) torch.Size([287])\n"
     ]
    }
   ],
   "source": [
    "data_test = WindTurbineDataset(\n",
    "    data_path  = data_path,\n",
    "    filename   = filename,\n",
    "    flag       = 'test',\n",
    "    size       = size,\n",
    "    task       = task,\n",
    "    target     = target,\n",
    "    start_col  = start_col,\n",
    "    turbine_id = turbine_id,\n",
    "    day_len    = day_len,\n",
    "    train_days = train_days,\n",
    "    val_days   = val_days,\n",
    "    test_days  = test_days,\n",
    "    total_days = total_days\n",
    ")\n",
    "\n",
    "print(len(data_test))\n",
    "t1x, t1y = data_test[1]\n",
    "print(t1x.shape, t1y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
